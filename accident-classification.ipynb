{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63643c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from time import perf_counter \n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d53cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining batch specfications\n",
    "batch_size = 100\n",
    "img_height = 250\n",
    "img_width = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e9e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading training set\n",
    "training_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'data/train',\n",
    "    seed=42,\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e075e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading validation dataset\n",
    "validation_data =  tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'data/val',\n",
    "    seed=42,\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7193b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading testing dataset\n",
    "testing_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'data/test',\n",
    "    seed=42,\n",
    "    image_size= (img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab12e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b59d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = training_data.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuring dataset for performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "training_data = training_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "testing_data = testing_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208b5e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining Cnn\n",
    "model = tf.keras.models.Sequential([\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Conv2D(32, 3, activation='relu'), # Conv2D(f_size, filter_size, activation) # relu, sigmoid, softmax\n",
    "  layers.MaxPooling2D(), # MaxPooling\n",
    "  layers.Conv2D(64, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(128, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(256, 3, activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(512, activation='relu'),\n",
    "  layers.Dense(len(class_names), activation= 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build((None, 250, 250, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8a0b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb52fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets train our CNN\n",
    "checkpoint = ModelCheckpoint(\"model_weights.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "history = model.fit(training_data, validation_data=validation_data, epochs = 20, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### serialize model structure to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b3f501",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stats on training data\n",
    "plt.plot(history.history['loss'], label = 'training loss')\n",
    "plt.plot(history.history['accuracy'], label = 'training accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8aa003",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stats on training data\n",
    "plt.plot(history.history['val_loss'], label = 'validation loss')\n",
    "plt.plot(history.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0b66ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets vizualize results on testing data\n",
    "AccuracyVector = []\n",
    "plt.figure(figsize=(30, 30))\n",
    "for images, labels in testing_data.take(1):\n",
    "    predictions = model.predict(images)\n",
    "    predlabel = []\n",
    "    prdlbl = []\n",
    "    \n",
    "    for mem in predictions:\n",
    "        predlabel.append(class_names[np.argmax(mem)])\n",
    "        prdlbl.append(np.argmax(mem))\n",
    "    \n",
    "    AccuracyVector = np.array(prdlbl) == labels\n",
    "    for i in range(40):\n",
    "        ax = plt.subplot(10, 4, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title('Pred: '+ predlabel[i]+' actl:'+class_names[labels[i]] )\n",
    "        plt.axis('off')\n",
    "        plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69eacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model__ = load_model(\"model_weights.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define class names manually or extract from another dataset\n",
    "class_names = ['Class 0', 'Class 1']  # Replace with actual class names\n",
    "\n",
    "# Initialize lists for true and predicted labels\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Iterate over testing data to collect true and predicted labels\n",
    "for images, labels in testing_data:\n",
    "    predictions = model.predict(images)  # Predict class probabilities\n",
    "    pred_classes = np.argmax(predictions, axis=1)  # Convert probabilities to class indices\n",
    "\n",
    "    # Append true and predicted labels\n",
    "    y_true.extend(labels.numpy())  # Convert tensor to numpy array and append\n",
    "    y_pred.extend(pred_classes)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_true, y_pred, average='binary')  # Use 'binary' for binary classification\n",
    "recall = recall_score(y_true, y_pred, average='binary')        # Use 'binary' for binary classification\n",
    "f1 = f1_score(y_true, y_pred, average='binary')                # Use 'binary' for binary classification\n",
    "accuracy = accuracy_score(y_true, y_pred)                      # No 'average' parameter for accuracy\n",
    "\n",
    "# Print metrics\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
